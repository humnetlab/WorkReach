---
title: "Multi-City Comparison of Commuter Flow Models"
subtitle: "A comparative study of spatial interaction models across different urban environments"
author: "Your Name"
date: today
format:
  html:
    page-layout: full
    body-width: 100%
    toc: true
    toc-depth: 3
    code-fold: true
    theme: cosmo
    html-math-method: katex
  pdf:
    pdf-engine: lualatex
    toc: true
    number-sections: true
    colorlinks: true
jupyter: python3
---

## Introduction

This notebook compares different models for predicting commuter flows across four major urban areas:

- Rio de Janeiro, Brazil
- Los Angeles, USA
- Bay Area, USA
- Mexico City, Mexico

We analyze multiple models:

1. Gravity model (power law decay)
2. Extended Radiation model
3. BMS Plausible model
4. Utility model (considering distance, economic complexity, and informality)

## Setup and Imports

```{python}
import numpy as np
import pandas as pd
import geopandas as gpd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from matplotlib.gridspec import GridSpec
import matplotlib.colors as mcolors
from matplotlib.cm import ScalarMappable
from matplotlib.colors import Normalize
import matplotlib.image as mpimg
from matplotlib.gridspec import GridSpec


from data_processing import *
from models import *
from evaluation import *
from visualization import *
from accessibility import *

plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams.update({
    'font.family': 'serif',
    'font.size': 12,
    'axes.labelsize': 14,
    'axes.titlesize': 16,
    'xtick.labelsize': 12,
    'ytick.labelsize': 12,
    'legend.fontsize': 12,
    'figure.titlesize': 18
})

warnings.filterwarnings('ignore')

CITY_COLORS = {
    "Rio de Janeiro": "#1f77b4",  
    "Los Angeles": "#ff7f0e",     
    "Bay Area": "#2ca02c",        
    "Mexico City": "#d62728"      
}

MODEL_COLORS = {
    "Utility": "#9b59b6",      
    "Gravity": "#f39c12",      
    "Radiation_Ext": "#1abc9c", 
    "BMS_Plausible": "#34495e" 
}
```

## Load Data for All Cities

```{python}
city_paths = {
    "Bay Area": {
        "mzn_path": "../data/h3_bay_8.geojson",
        "flows_path": "../data/bay_flows_h3_8.csv"
    },
    "Los Angeles": {
        "mzn_path": "../data/h3_la_8.geojson",
        "flows_path": "../data/la_flows_h3_8.csv"
    },
    "Mexico City": {
        "mzn_path": "../data/h3_cdmx_8.geojson",
        "flows_path": "../data/cdmx_flows_h3_8.csv"
    },
    "Rio de Janeiro": {
        "mzn_path": "../data/map_informality_eci.geojson",
        "flows_path": "../data/rio_flows_h3_8h3.csv"
    }
}

def process_all_cities(city_paths):
    results = {}

    for city_name, paths in city_paths.items():
        print(f"\nProcessing {city_name}...")

        try:
            city_data = {}
            (aligned_data, mzn, distance_matrix, eci_matrix, flows_matrix,
             home_matrix, informality_matrix, _) = load_and_prepare_data(
                paths["mzn_path"], paths["flows_path"], city_name)

            median_point = mzn["informality_rate"].median()
            aligned_data['informality_level'] = np.where(
                aligned_data['informality_rate'] < median_point, 'Low', 'High'
            )

            (distance, distance_log, eci, flows, informality,
             home_population, work_population,distance_min,
             distance_diff, eci_min, eci_diff) = preprocess_data(
                home_matrix, distance_matrix, eci_matrix, flows_matrix, informality_matrix)

            flow_map_data = prepare_flow_map_data(aligned_data, mzn)

            city_data["aligned_data"] = aligned_data
            city_data["mzn"] = mzn
            city_data["distance_matrix"] = distance_matrix
            city_data["eci_matrix"] = eci_matrix
            city_data["flows_matrix"] = flows_matrix
            city_data["home_matrix"] = home_matrix
            city_data["informality_matrix"] = informality_matrix
            city_data["distance"] = distance
            city_data["distance_log"] = distance_log
            city_data["eci"] = eci
            city_data["eci_min"] = eci_min
            city_data["eci_diff"] = eci_diff
            city_data["distance_min"] = distance_min
            city_data["distance_diff"] = distance_diff
            city_data["flows"] = flows
            city_data["informality"] = informality
            city_data["home_population"] = home_population
            city_data["work_population"] = work_population
            city_data["flow_map_data"] = flow_map_data

            print(f"  Loaded data: {len(mzn)} zones, {len(aligned_data)} flows")

            results[city_name] = city_data

        except Exception as e:
            print(f"Error processing {city_name}: {str(e)}")

    return results

all_city_data = process_all_cities(city_paths)
```

## City Characteristics and Data Summary

```{python}
all_summaries = []

for city_name, city_data in all_city_data.items():
    summary = create_dataset_summary_table(
        city_data["aligned_data"],
        city_data["mzn"],
        city_name
    )
    all_summaries.append(summary)

combined_summary = pd.concat(all_summaries)

print("City Comparison - Basic Statistics:")
display(combined_summary)
```

## Fit Models for All Cities

```{python}
def fit_all_models(city_data):
    models_dict = {}

    try:
        print("  Optimizing Utility model...")
        optimized_params_utility, predicted_flows_utility = optimize_utility_model(
            city_data["distance_log"], city_data["eci"], city_data["flows"],
            city_data["informality"], city_data["home_population"], True
        )
        models_dict["Utility"] = (optimized_params_utility, predicted_flows_utility, 5)
    except Exception as e:
        print(f"  Error in Utility model: {str(e)}")

    try:
        print("  Optimizing Gravity model with power law decay...")
        optimized_params_gravity_pow, predicted_flows_gravity_pow = optimize_gravity_pow_model(
            city_data["distance"], city_data["home_population"],
            city_data["work_population"], city_data["flows"]
        )
        models_dict["Gravity"] = (optimized_params_gravity_pow, predicted_flows_gravity_pow, 4)
    except Exception as e:
        print(f"  Error in Gravity model (power law): {str(e)}")

    try:
        print("  Optimizing Extended Radiation model...")
        alpha_opt, predicted_flows_radiation_ext = optimize_radiation_extended(
            city_data["distance"], city_data["home_population"],
            city_data["work_population"], city_data["flows"]
        )
        models_dict["Radiation_Ext"] = (alpha_opt, predicted_flows_radiation_ext, 1)
    except Exception as e:
        print(f"  Error in Radiation Extended model: {str(e)}")

    try:
        print("  Optimizing BMS Plausible model...")
        optimized_params_bms_plausible, predicted_flows_bms_plausible = optimize_bms_plausible_model(
            city_data["distance"], city_data["home_population"],
            city_data["work_population"], city_data["flows"]
        )
        models_dict["BMS_Plausible"] = (optimized_params_bms_plausible, predicted_flows_bms_plausible, 6)
    except Exception as e:
        print(f"  Error in BMS Plausible model: {str(e)}")

    return models_dict

all_models = {}
for city_name, city_data in all_city_data.items():
    print(f"\nFitting models for {city_name}...")
    all_models[city_name] = fit_all_models(city_data)
```

## Model Performance Comparison Across Cities

```{python}
def extract_performance_metrics(all_city_data, all_models):
    performance_dfs = []

    for city_name, models_dict in all_models.items():
        city_data = all_city_data[city_name]

        comparison_df, _ = compare_models(models_dict, city_data["flows"])
        comparison_df["City"] = city_name

        performance_dfs.append(comparison_df)

    return pd.concat(performance_dfs)

all_performance = extract_performance_metrics(all_city_data, all_models)

def create_metric_pivot(all_performance, metric):
    pivot = all_performance.pivot(index="Model", columns="City", values=metric)
    pivot.loc["Average"] = pivot.mean()
    pivot["Average"] = pivot.mean(axis=1)
    return pivot

cpc_pivot = create_metric_pivot(all_performance, "CPC")
print("\nCommon Part of Commuters (CPC) by City and Model:")
display(cpc_pivot.style.format("{:.4f}"))

corr_pivot = create_metric_pivot(all_performance, "Correlation")
print("\nCorrelation by City and Model:")
display(corr_pivot.style.format("{:.4f}"))
```

## Model Performance Visualization

```{python}
model_types = ["Gravity", "Radiation_Ext", "Utility", "BMS_Plausible"]
cities_list = list(all_city_data.keys())

fig, axes = plt.subplots(len(cities_list), len(model_types), figsize=(16, 16))

for i, city in enumerate(cities_list):
    city_data = all_city_data[city]
    city_models = all_models[city]
    flows = city_data["flows"]

    for j, model in enumerate(model_types):
        ax = axes[i, j]

        if model not in city_models:
            ax.text(0.5, 0.5, "Model not available", ha='center', va='center')
            continue

        _, predicted_flows, _ = city_models[model]

        flows_flat = flows.flatten()
        pred_flat = np.round(predicted_flows).flatten()

        mask = ~np.isnan(flows_flat) & ~np.isnan(pred_flat)
        flows_plot = flows_flat[mask]
        pred_plot = pred_flat[mask]

        from scipy.stats import pearsonr
        corr = np.corrcoef(flows_plot, pred_plot)[0, 1]
        cpc = common_part_of_commuters(flows_plot, pred_plot)

        ax.scatter(flows_plot, pred_plot, s=10, alpha=0.01, color=MODEL_COLORS.get(model, "blue"), rasterized=True)

        max_val = max(np.max(flows_plot), np.max(pred_plot))
        ax.plot([0, max_val], [0, max_val], 'r--', alpha=0.88)

        ax.text(0.05, 0.95, f"$\\rho$ = {corr:.2f}\nCPC = {cpc:.2f}",
            transform=ax.transAxes, fontsize=20,
            verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))

        if model == "Utility":
            model_display = "WorkReach"
        else:
            model_display = model.replace("_", " ")

        if i == 0:
            ax.set_title(model_display)

        if j == 0:
            ax.set_ylabel(f"{city}\nPredicted Flows")

        if i == len(cities_list) - 1:
            ax.set_xlabel("Observed Flows")

        ax.set_xscale('log')
        ax.set_yscale('log')

        ax.set_xlim(1, max_val*1.1)
        ax.set_ylim(1, max_val*1.1)

fig.savefig("../figs/model_performance.pdf", dpi=300, bbox_inches="tight")
plt.tight_layout()
plt.show()
```

## Utility Model Parameters Comparison

```{python}
utility_params_tables = []

for city_name, models_dict in all_models.items():
    if "Utility" in models_dict:
        params, _, _ = models_dict["Utility"]
        params_copy = params.copy()
        params_copy[3] = (params_copy[3] * all_city_data[city_name]["distance_diff"] + all_city_data[city_name]["distance_min"])/1000
        params_table = create_utility_model_parameters_table(params_copy, city_name)
        utility_params_tables.append(params_table)

combined_utility_params = pd.concat(utility_params_tables)

print("\nUtility Model Parameters Across Cities:")
display(combined_utility_params)

utility_params_fig = plot_utility_parameters(combined_utility_params)
plt.show()
```

## Accessibility Analysis

```{python}
combined_accessibility_df, all_accessibility_dfs = process_accessibility_data(all_city_data, all_models)

city_order = ["Bay Area", "Los Angeles", "Mexico City", "Rio de Janeiro"]
accessibility_fig = create_accessibility_boxplots(combined_accessibility_df, city_order)
accessibility_fig.savefig('../figs/accessibility_boxplots_sharey.pdf', dpi=300,
                          facecolor='white', edgecolor='none')
plt.show()
```

## Variable Maps with Histograms

```{python}
city_order = ["Bay Area", "Los Angeles", "Mexico City", "Rio de Janeiro"]
maps_fig = create_maps_with_histograms(all_city_data, city_order)
maps_fig.savefig('../figs/maps_hist.pdf', dpi=300,
                 facecolor='white', edgecolor='none')
maps_fig.savefig('../figs/maps_hist.png', dpi=300, bbox_inches='tight',
                 facecolor='white', edgecolor='none')
plt.show()
```

## Accessibility Maps

```{python}
from scipy import stats

z_df = (
    combined_accessibility_df
    .assign(
        z_dist=lambda d: d.groupby('City')['distance_weighted_accessibility']
                          .transform(stats.zscore, nan_policy='omit'),
        z_surp=lambda d: d.groupby('City')['surplus_accessibility']
                          .transform(stats.zscore, nan_policy='omit')
    )
)

def winsorise(series, lower=0.05, upper=.95):
    lo, hi = series.quantile([lower, upper])
    return series.clip(lo, hi)

z_df['z_dist'] = z_df.groupby('City')['z_dist'].transform(winsorise)
z_df['z_surp'] = z_df.groupby('City')['z_surp'].transform(winsorise)

from sklearn.decomposition import PCA

def winsorise_and_pca(series, p_lo=.05, p_hi=.95):
    lo, hi = series.quantile([p_lo, p_hi])
    return series.clip(lo, hi)

for col in ["z_dist", "z_surp"]:
    z_df[col] = z_df.groupby("City")[col].transform(winsorise_and_pca)

z_df[["z_dist", "z_surp"]] = (
    z_df.groupby("City")[["z_dist", "z_surp"]]
        .transform(lambda x: (x - x.mean()) / x.std(ddof=0))
)
z_df = z_df.dropna()

def city_pca(sub):
    pcs = PCA(n_components=2).fit_transform(sub[["z_dist", "z_surp"]])
    sub[["PC1","PC2"]] = pcs
    return sub

z_df = z_df.groupby("City").apply(city_pca).drop(columns="City").reset_index()
z_df["diff"] = z_df["PC1"].transform(winsorise_and_pca)

sns.set_theme(context="talk", style="whitegrid")
plt.rcParams.update({
    "axes.titlesize": 36, "axes.labelsize": 32,
    "xtick.labelsize": 28, "ytick.labelsize": 28,
    "legend.fontsize": 36, "figure.figsize": (24, 18)
})

city_order = ["Bay Area", "Los Angeles", "Mexico City", "Rio de Janeiro"]

ROW_INFO = [
    ("z_dist", "crest_r", False, "a)  Distance-weighted Accessibility"),
    ("z_surp", "viridis", False, "b)  Consumer Surplus Accessibility"),
    ("diff", "flare_r", False, "c)  PCA 1st Dim. Accessibility")
]

fig, axes = plt.subplots(3, 4, figsize=(24, 18), gridspec_kw={"hspace": 0.25, "wspace": 0.12})

for c, city in enumerate(city_order):
    fig.text(0.20 + c * 0.21, 0.955, city,
             fontsize=38, fontweight="bold", ha="center", va="top")

for r, (metric, cmap, div, *_) in enumerate(ROW_INFO):
    for c, city in enumerate(city_order):
        ax = axes[r, c]
        gdf_city = all_city_data[city]["mzn"].merge(
            z_df[z_df.City == city][["geomid", metric]],
            on="geomid", how="left"
        )

        vmin, vmax = gdf_city[metric].min(), gdf_city[metric].max()
        gdf_city.plot(column=metric, cmap=cmap, ax=ax,
                     vmin=vmin, vmax=vmax, linewidth=0.1, edgecolor='white',
                     missing_kwds=dict(color="lightgrey", label="NA"))
        ax.set_axis_off()

for r, (_, _, _, row_label) in enumerate(ROW_INFO):
    ax_pos = axes[r, 0].get_position()
    row_top_y = ax_pos.y0 + ax_pos.height + 0.02
    fig.text(0.04, row_top_y, row_label,
             fontsize=34, fontweight="bold", va="bottom")

plt.tight_layout(rect=[0.06, 0.01, 0.98, 0.91])
fig.savefig('../figs/accessibility_maps_space.pdf', dpi=300,
            facecolor='white', edgecolor='none')
fig.savefig('../figs/accessibility_maps_space.png', dpi=300, bbox_inches='tight',
            facecolor='white', edgecolor='none')
plt.show()
```

## Complexity Analysis (for complexity_plots.pdf)

```{python}
# Note: This requires running the complexity analysis from analysis_eci.qmd
# Placeholder

print("Complexity analysis would go here - integrate from analysis_eci.qmd if needed")
print("This creates the complexity_plots.pdf figure")
```

## Four Panel Layout (for four_panel_layout_workreach_font.pdf)

```{python}
try:
    ipath = "../figs"
    img_a = mpimg.imread(f"{ipath}/cdmx_stacked_variables.png")
    img_b = mpimg.imread(f"{ipath}/cdmx_utility_job_location.png")
    img_c = mpimg.imread(f"{ipath}/cdmx_flows_workreach.png")
    img_d = mpimg.imread(f"{ipath}/substitution_rates_cdmx.png")

    fig = plt.figure(figsize=(18, 12), constrained_layout=True)
    gs = GridSpec(2, 3, height_ratios=[2.5, 2], figure=fig)

    ax_a = fig.add_subplot(gs[0, 0])
    ax_b = fig.add_subplot(gs[0, 1])
    ax_c = fig.add_subplot(gs[0, 2])
    ax_d = fig.add_subplot(gs[1, :])

    for ax, img in zip([ax_a, ax_b, ax_c, ax_d], [img_a, img_b, img_c, img_d]):
        ax.imshow(img)
        ax.axis("off")

    fig.text(0.065, 0.965, "a)", fontsize=28, fontweight="bold", ha="left", va="top", color="black")
    fig.text(0.38, 0.965, "b)", fontsize=28, fontweight="bold", ha="left", va="top", color="black")
    fig.text(0.705, 0.965, "c)", fontsize=28, fontweight="bold", ha="left", va="top", color="black")
    fig.text(0.02, 0.48, "d)", fontsize=28, fontweight="bold", ha="left", va="top", color="black")

    fig.savefig("../figs/four_panel_layout_workreach_font.pdf", dpi=300, bbox_inches="tight")
    plt.show()

except FileNotFoundError:
    print("Image files not found - please adjust paths in the four panel layout section")
    print("This creates the four_panel_layout_workreach_font.pdf figure")
```

